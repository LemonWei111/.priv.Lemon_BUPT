{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44185084-2542-4c7d-ace9-30c5b892262f",
   "metadata": {},
   "source": [
    "一、任务说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dea9a1-f38d-4bed-9760-4ec7e9c182ef",
   "metadata": {},
   "source": [
    "训练vgg19整体表示+GRU模型，验证功能，选择相对合适的嵌入系统的模型参数文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e53c7b-c210-425f-9c7f-d824455e3787",
   "metadata": {},
   "source": [
    "二、实验数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3006510-03bc-4904-821e-68ee318dcc29",
   "metadata": {},
   "source": [
    "\n",
    "1、训练数据（参见getdata.py说明）\n",
    "\n",
    "2、功能验证数据：\n",
    "\n",
    "（1）随机选取的男女图片各一张，重命名为m/w_test1.jpg。\n",
    "旨在观察能否区分男女性别差异，生成不一样的图片描述。\n",
    "\n",
    "（2）随机生成的与图片预处理输入模型时大小一致的张量。\n",
    "旨在观察模型应对随机数据的能力，能否生成贴切的图片描述，是否存在“编造”的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd56e02-f354-43fd-a7a9-8ef48561867e",
   "metadata": {},
   "source": [
    "三、实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a18073-42d0-4b45-87ff-86395e34c6b6",
   "metadata": {},
   "source": [
    "\n",
    "1、环境配置要求：4核CPU+8GB内存+1卡GPU\n",
    "\n",
    "2、操作系统：Windows10+Linux\n",
    "\n",
    "3、编写环境：jupyter lab\n",
    "\n",
    "4、深度学习框架：依赖于深度学习框架PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ddcc8-57e6-478b-93b1-e643260b8d0c",
   "metadata": {},
   "source": [
    "四、所用的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc0da6-92a8-43da-b099-7a9f8dc7681e",
   "metadata": {},
   "source": [
    "1、使用vgg19整体表示+GRU模型训练实现有监督训练。（模型详细说明参见modelcr.py）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be51800b-37d1-4321-81ec-acd34333a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/u2021213513/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u2021213513/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "#引入评测指标，文本序列转文本的函数\n",
    "from evaluate import evaluate_bleu_4, evaluate_rouge_l, fromtexttosentence\n",
    "#引入词汇表生成函数，训练、验证、测试集划分函数\n",
    "from getdata import words, mktrainvaltest\n",
    "#引入模型定义\n",
    "from modelcr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d975d7-6f97-4905-9813-5e85f3f8a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, 'is': 2, 'The': 3, 'a': 4, 'with': 5, 'fabric': 6, 'and': 7, 'patterns': 8, 'wears': 9, 'color': 10, 'cotton': 11, 'has': 12, 'her': 13, 'This': 14, 'on': 15, 'There': 16, 'shirt': 17, 'neckline': 18, 'tank': 19, 'pants': 20, 'pure': 21, 'solid': 22, 'are': 23, 'of': 24, 'an': 25, 'person': 26, 'ring': 27, 'long': 28, 'accessory': 29, ',': 30, 'wearing': 31, 'female': 32, 'lady': 33, 'wrist': 34, 'sleeves': 35, 'trousers': 36, 'graphic': 37, 'finger': 38, 'it': 39, 'clothing': 40, 'denim': 41, 'three-point': 42, 'shorts': 43, 'It': 44, 'top': 45, 'length': 46, 'the': 47, 'woman': 48, 'its': 49, 'in': 50, 'round': 51, 'sweater': 52, 'this': 53, 'crew': 54, 'his': 55, 'chiffon': 56, 'outer': 57, 'long-sleeve': 58, 'neck': 59, 'Her': 60, 'neckwear': 61, 'T-shirt': 62, 'hat': 63, 'short': 64, 'suspenders': 65, 'sleeveless': 66, 'short-sleeve': 67, 'upper': 68, 'lower': 69, 'v-shape': 70, 'knitting': 71, 'cut': 72, 'off': 73, 'no': 74, 'floral': 75, 'lapel': 76, 'head': 77, 'medium': 78, 'also': 79, 'socks': 80, 'guy': 81, 'pattern': 82, 'leather': 83, 'gentleman': 84, 'skirt': 85, 'pair': 86, 'other': 87, 'striped': 88, 'belt': 89, 'stripe': 90, 'three-quarter': 91, 'sunglasses': 92, 'waist': 93, 'shoes': 94, 'medium-sleeve': 95, 'complicated': 96, 'man': 97, 'block': 98, 'leggings': 99, 'stand': 100, 'His': 101, 'lattice': 102, 'plaid': 103, 'furry': 104, 'mixed': 105, 'square': 106, 'glasses': 107, 'hands': 108, 'or': 109, 'clothes': 110, '<start>': 111, '<end>': 112, '<pad>': 0}\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "#test words:\n",
    "train_path = './deepfashion-multimodal/train_captions.json'\n",
    "all_words = words(train_path)\n",
    "print(all_words)\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8992e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#算力资源有限，为避免频繁be killed，放弃了加大batch并行加载数据\n",
    "test_path = './deepfashion-multimodal/test_captions.json'\n",
    "batch_size = 1\n",
    "train_data_loader, val_data_loader, test_data_loader = mktrainvaltest(train_path, test_path, all_words, batch_size, workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e939f1e-c51b-4c08-8335-34b471217b92",
   "metadata": {},
   "source": [
    "2、损失函数与超参数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b40ac",
   "metadata": {},
   "source": [
    "\n",
    "（1）损失函数：移除<pad>，计算交叉熵损失\n",
    "\n",
    "（2）超参数设置：\n",
    "\n",
    "①生成参数：max_len最大的生成长度为100，使用bleu_4指标评测时为每张图像生成的描述数captions_per_image为5，束搜索宽度beam_k为5。\n",
    "\n",
    "②神经网络有关参数：image_code_dim编码器编码后的图像维度为4096，词嵌入维度word_dim为512，GRU解码器隐藏层hidden_size大小512，层数num_layers为1。\n",
    "\n",
    "③学习率：encoder_learning_rate = 0.00001，decoder_learning_rate = 0.0005。\n",
    "\n",
    "④训练epoch：num_epochs = 10。\n",
    "\n",
    "⑤最大裁剪梯度：grad_clip = 5.0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d818f00c-2487-43f7-a5b4-c3b0b6c3595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/MYMODL/last.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MYMODL(\n",
       "  (encoder): ImageEncoder(\n",
       "    (image_encoder): VGG(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace=True)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace=True)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (11): ReLU(inplace=True)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace=True)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace=True)\n",
       "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (17): ReLU(inplace=True)\n",
       "        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (20): ReLU(inplace=True)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace=True)\n",
       "        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (24): ReLU(inplace=True)\n",
       "        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (26): ReLU(inplace=True)\n",
       "        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (29): ReLU(inplace=True)\n",
       "        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (31): ReLU(inplace=True)\n",
       "        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (33): ReLU(inplace=True)\n",
       "        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (35): ReLU(inplace=True)\n",
       "        (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "      (classifier): Sequential(\n",
       "        (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "        (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(113, 512)\n",
       "    (init_state): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (rnn): GRU(4608, 512)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=512, out_features=113, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PackedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PackedCrossEntropyLoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, predictions, targets, lengths):\n",
    "        \"\"\"\n",
    "        参数：\n",
    "            predictions：按文本长度排序过的预测结果\n",
    "            targets：按文本长度排序过的文本描述\n",
    "            lengths：文本长度\n",
    "        \"\"\"\n",
    "        predictions = pack_padded_sequence(predictions, lengths, batch_first=True)[0]\n",
    "        targets = pack_padded_sequence(targets, lengths, batch_first=True)[0]\n",
    "        #print(predictions)\n",
    "        #print(targets.add(-1))\n",
    "        return self.loss_fn(predictions, targets.add(0))\n",
    "def get_optimizer(model, encoder_learning_rate, decoder_learning_rate):\n",
    "    return torch.optim.Adam([{\"params\": filter(lambda p: p.requires_grad, model.encoder.parameters()), \n",
    "                              \"lr\": encoder_learning_rate},\n",
    "                             {\"params\": filter(lambda p: p.requires_grad, model.decoder.parameters()), \n",
    "                              \"lr\": decoder_learning_rate}])\n",
    "# 设置模型超参数和辅助变量\n",
    "max_len = 100\n",
    "captions_per_image = 5\n",
    "image_code_dim = 4096\n",
    "word_dim = 512\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "encoder_learning_rate = 0.00001\n",
    "decoder_learning_rate = 0.0005\n",
    "num_epochs = 10\n",
    "grad_clip = 5.0\n",
    "\n",
    "evaluate_step = 300 # 每隔多少步在验证集上测试一次\n",
    "best_checkpoint_for_rouge = './model/MYMODL/best_rouge.ckpt' # 验证集上表现最优的模型的路径\n",
    "best_checkpoint_for_bleu = './model/MYMODL/best_bleu.ckpt' # 验证集上表现最优的模型的路径\n",
    "last_checkpoint = './model/MYMODL/last.ckpt' # 训练完成时的模型的路径\n",
    "beam_k = 5\n",
    "import os\n",
    "# 设置GPU信息\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "# 模型\n",
    "# 随机初始化 或 载入已训练的模型\n",
    "start_epoch = 0\n",
    "checkpoint = last_checkpoint#None # 如果不为None，则利用该变量路径的模型继续训练\n",
    "print(checkpoint)\n",
    "if checkpoint is None:\n",
    "    print(\"随机初始化\")\n",
    "    model = MYMODL(image_code_dim, all_words, word_dim, hidden_size, num_layers)\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model = checkpoint['model']\n",
    "\n",
    "# 优化器\n",
    "optimizer = get_optimizer(model, encoder_learning_rate, decoder_learning_rate)\n",
    "\n",
    "# 将模型拷贝至GPU，并开启训练模式\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78365f35-1aa1-4a94-bd84-9b27b27b42c5",
   "metadata": {},
   "source": [
    "五、实验结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0916513-fc42-4a8c-84a3-816b8dd453b1",
   "metadata": {},
   "source": [
    "1、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9daa1d58-db5f-431b-9f83-b128333f09ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "epoch 1, step 1000: loss=0.53, time=505.19\n",
      "epoch 1, step 1100: loss=0.67, time=1032.10\n",
      "epoch 1, step 1200: loss=0.88, time=1555.68\n",
      "Validation@epoch, 1, step, 1200, BLEU-4=0.68\n",
      "Validation@epoch, 1, step, 1200, rouge-l=0.17\n",
      "epoch 1, step 1300: loss=0.69, time=4159.67\n",
      "epoch 1, step 1400: loss=0.37, time=4675.91\n",
      "epoch 1, step 1500: loss=0.64, time=5153.73\n",
      "Validation@epoch, 1, step, 1500, BLEU-4=0.74\n",
      "Validation@epoch, 1, step, 1500, rouge-l=0.17\n",
      "epoch 1, step 1600: loss=0.65, time=7749.80\n",
      "epoch 1, step 1700: loss=0.49, time=8225.30\n",
      "epoch 1, step 1800: loss=0.46, time=8710.16\n",
      "Validation@epoch, 1, step, 1800, BLEU-4=0.65\n",
      "Validation@epoch, 1, step, 1800, rouge-l=0.18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/2134447971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_captions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m# 梯度截断\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrad_clip\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# 损失函数\n",
    "loss_fn = PackedCrossEntropyLoss().to(device)\n",
    "\n",
    "best_res_for_bleu = 0\n",
    "best_res_for_rouge = 0\n",
    "print(\"开始训练\")\n",
    "#不清空：a；清空：w\n",
    "fw = open('log.txt', 'a')\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    start_time = time.time()\n",
    "    for i, (imgs, caps, caplens) in enumerate(train_data_loader):\n",
    "        #接着训练\n",
    "        if (i > 1800):\n",
    "            optimizer.zero_grad()\n",
    "            # 1. 读取数据至GPU\n",
    "            imgs = imgs.to(device)\n",
    "            caps = caps.to(device)\n",
    "            caplens = caplens.to(device)\n",
    "\n",
    "            # 2. 前馈计算\n",
    "            predictions, sorted_captions, lengths, sorted_cap_indices = model(imgs, caps, caplens)\n",
    "            # 3. 计算损失\n",
    "            # captions从第2个词开始为targets\n",
    "            loss = loss_fn(predictions, sorted_captions[:, 1:], lengths)\n",
    "\n",
    "            loss.backward()\n",
    "            # 梯度截断\n",
    "            if grad_clip > 0:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            # 4. 更新参数\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                i_time = time.time() - start_time\n",
    "                print('epoch %d, step %d: loss=%.2f, time=%.2f' % (epoch, i+1, loss.cpu(), i_time))\n",
    "                fw.write('epoch %d, step %d: loss=%.2f \\n' % (epoch, i+1, loss.cpu()))\n",
    "                fw.flush()\n",
    "                torch.save(model, f'./model/MYMODL/mymodl_{epoch}_{i}.pth')\n",
    "\n",
    "            state = {\n",
    "                    'epoch': epoch,\n",
    "                    'step': i,\n",
    "                    'model': model,\n",
    "                    'optimizer': optimizer\n",
    "                    }\n",
    "            if (i+1) % evaluate_step == 0:\n",
    "                #如果有必要，val可以从train里面分（交叉验证），否则用test\n",
    "                bleu_score = evaluate_bleu_4(val_data_loader, model, captions_per_image, beam_k, max_len)\n",
    "                rouge_score = evaluate_rouge_l(val_data_loader, model, beam_k, max_len)\n",
    "\n",
    "                # 5. 选择模型\n",
    "                if best_res_for_bleu < bleu_score:\n",
    "                    best_res_for_bleu = bleu_score\n",
    "                    torch.save(state, best_checkpoint_for_bleu)\n",
    "                if best_res_for_rouge < rouge_score:\n",
    "                    best_res_for_rouge = rouge_score\n",
    "                    torch.save(state, best_checkpoint_for_rouge)\n",
    "                torch.save(state, last_checkpoint)\n",
    "                fw.write('Validation@epoch, %d, step, %d, BLEU-4=%.2f\\n' % \n",
    "                      (epoch, i+1, bleu_score))\n",
    "                fw.write('Validation@epoch, %d, step, %d, rouge-l=%.2f\\n' % \n",
    "                      (epoch, i+1, rouge_score))\n",
    "                fw.flush()\n",
    "                print('Validation@epoch, %d, step, %d, BLEU-4=%.2f' % \n",
    "                      (epoch, i+1, bleu_score))\n",
    "                print('Validation@epoch, %d, step, %d, rouge-l=%.2f' % \n",
    "                      (epoch, i+1, rouge_score))\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ac531-9588-488b-8f18-fe2ae3ec15e1",
   "metadata": {},
   "source": [
    "2、功能验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e89ade1-fc0b-45bc-8916-75c88db1fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from api import translate\n",
    "def get_image(file_path):\n",
    "    # 读取图像\n",
    "    image = Image.open(file_path)\n",
    "    image = image.convert('RGB')\n",
    "    tx = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    #try2\n",
    "    if tx is not None:\n",
    "        image = tx(image).unsqueeze(0)\n",
    "    return image\n",
    "imgs = get_image('./sample_images/w_test1.jpg')\n",
    "imgl = torch.randn(1, 3, 224, 224)\n",
    "print(imgs.shape)\n",
    "print(imgl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1e9d61f-9727-43e3-83ac-8aa5b7ca5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward1>)\n",
      "[[111, 60, 19, 45, 12, 74, 35, 30, 11, 6, 7, 21, 10, 8, 1, 3, 18, 24, 39, 2, 54, 1, 3, 69, 40, 2, 24, 42, 46, 1, 3, 6, 2, 41, 7, 39, 12, 22, 10, 8, 1, 112]]\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<ReluBackward1>)\n",
      "[[111, 3, 68, 40, 12, 64, 35, 30, 11, 6, 7, 21, 10, 8, 1, 3, 18, 24, 39, 2, 54, 1, 3, 69, 40, 2, 24, 42, 46, 1, 3, 6, 2, 41, 7, 39, 12, 22, 10, 8, 1, 112]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "e_textss = model.generate_by_beamsearch(imgs, 5, 102)\n",
    "print(model.encoder(imgs))\n",
    "print(e_textss)\n",
    "e_textsl = model.generate_by_beamsearch(imgl, 5, 102)\n",
    "print(model.encoder(imgl))\n",
    "print(e_textsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8d7bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>她的背心没有袖子，棉质面料和纯色图案。它的领口是圆领的。下面的衣服有三分长。面料是牛仔布，有纯色图案<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它的领口是圆领的。下面的衣服有三分长。面料是牛仔布，有纯色图案<end>\n"
     ]
    }
   ],
   "source": [
    "print(translate(fromtexttosentence(e_textss, all_words)))\n",
    "print(translate(fromtexttosentence(e_textsl, all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f2eadc6-50ec-4163-8112-0e53ba22af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgm = get_image('./sample_images/m_test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1729a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>她的背心没有袖子，棉质面料和纯色图案。它的领口是圆领的。下面的衣服有三分长。面料是牛仔布，有纯色图案。她的手腕上有一个配件<end>\n"
     ]
    }
   ],
   "source": [
    "e_textsm = model.generate_by_beamsearch(imgm, 5, 102)\n",
    "print(translate(fromtexttosentence(e_textsm, all_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245698e8-0179-4178-966d-475a9fb7132e",
   "metadata": {},
   "source": [
    "六、实验结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f76a2-222f-4bfc-b44c-a77531005f52",
   "metadata": {},
   "source": [
    "\n",
    "1、loss:\n",
    "\n",
    "据上述实验结果和log.txt日志记录，loss在训练时波动减小，说明模型正在学习，且并未达到最优。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d514b-9a5e-4f4f-b38e-f6e4b410aa8c",
   "metadata": {},
   "source": [
    "2、best_bleu_4（原理与实现参见evaluate.py）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07d44f-ff67-4f7b-8264-659e8041dea0",
   "metadata": {},
   "source": [
    "\n",
    "（1）偶尔出现bleu为0的情况。\n",
    "\n",
    "可能原因：该现象曾出现在一个epoch没训完下一个epoch继续从step1开始训练的时候，预测得到<start><end>，模型学习不到数据，可能是早期训练模型见的数据少的缘故，波动也就有了。\n",
    "\n",
    "（2）bleu大小与模型生成描述与图片贴合度没有直接关联。\n",
    "\n",
    "我们观察到，best_bleu有可能不如最后一次模型训练输出的效果好，生成的描述呈现高度重合性，相反，在输入图片数据随机性越大时，描述反而越丰富（虽然不一定贴切）。观察imageencoder之后的输出，认为可能是在编码器较简单、编码器解码器学习率相差不大的情况下，出现了一种“编解码无限拟合”的情况，让解码器认为输入的值是固定和相似的，编码器则认为要将图像编码为相似输出的，整体特征和归一化同时也加大了这种相似性，因而在小的epoch下，很难让这种差异更加明显，也就相对难以实现图片描述生成的多样性，因为我们的解码器倾向于生成更多它见过的词汇，这些词汇可能反映模型目前见过的数据的普遍特征（比如，我们可以推测，数据集中女性图片数据多于男性，且描述文本中对男性的描述往往、较少出现“a man”“a male”“he”“his”等词汇，因为模型总是认为一个图片是女性，而很少明确地说“他”）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba0faad-a5d2-431b-8823-bf747963099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>此人穿着纯色图案的无袖背心。这件背心是棉布的。它有一个吊带领口。这位女士穿的裤子有三分长。这条裤子采用棉布和图案。她的手腕上有一个配件<end>\n",
      "<start>此人穿着纯色图案的无袖背心。这件背心是棉布的。它有一个吊带领口。这位女士穿的裤子有三分长。这条裤子采用棉布和图案。她的手腕上有一个配件<end>\n",
      "<start>这位女士穿着一件纯色图案的无袖背心和一条长裤。这件背心是棉布的。这条裤子采用棉布和图案。这位女士戴着一枚戒指<end>\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(best_checkpoint_for_bleu)\n",
    "model = checkpoint['model']\n",
    "model.eval()\n",
    "e_textss = model.generate_by_beamsearch(imgs, 5, 102)\n",
    "e_textsm = model.generate_by_beamsearch(imgm, 5, 102)\n",
    "e_textsl = model.generate_by_beamsearch(imgl, 5, 102)\n",
    "print(translate(fromtexttosentence(e_textss, all_words)))\n",
    "print(translate(fromtexttosentence(e_textsm, all_words)))\n",
    "print(translate(fromtexttosentence(e_textsl, all_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b73e9-a7a6-4d1d-ad6e-f46637455dab",
   "metadata": {},
   "source": [
    "3、best_rouge_l（原理与实现参见evaluate.py）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13516e0f-0559-410f-ac7b-105b265c9a9d",
   "metadata": {},
   "source": [
    "\n",
    "（1）偶尔出现rouge为0的情况。\n",
    "\n",
    "可能原因：与bleu类似。\n",
    "\n",
    "（2）初步观察发现，rouge大小可能与模型生成描述多样性有关，rouge更小的情况下，主观观察模型对不同图片生成的描述更丰富。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc52ac87-bffb-4f5f-8b88-4cc43d77dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(best_checkpoint_for_rouge)\n",
    "model = checkpoint['model']\n",
    "model.eval()\n",
    "e_textss = model.generate_by_beamsearch(imgs, 5, 102)\n",
    "e_textsm = model.generate_by_beamsearch(imgm, 5, 102)\n",
    "e_textsl = model.generate_by_beamsearch(imgl, 5, 102)\n",
    "print(translate(fromtexttosentence(e_textss, all_words)))\n",
    "print(translate(fromtexttosentence(e_textsm, all_words)))\n",
    "print(translate(fromtexttosentence(e_textsl, all_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2127c-22b4-477e-aea8-9a9aab8779a0",
   "metadata": {},
   "source": [
    "在实验中还观察到，rouge与bleu相比明显更小，波动更弱，说明该评测标准在本实验下相对更严格也更难优化，参考价值或许不如bleu，因而后续模型可以考虑采用bleu来进行评测，或者尝试引入其他的指标如准确率等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebcc5008-d4f8-470f-ae17-c92a51939fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "<start>戴戒指的人手腕上戴着戒指。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。有\n",
      "<start>戴戒指的人手腕上戴着戒指。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件。她的手腕上有一个配件<end>\n",
      "<start>这件衬衫有袖子、袖子、袖子，棉质面料和纯色图案。这只雌性的手指上戴着一枚戒指。这只雌性的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。她的手指上戴着一枚戒指。\n",
      "199\n",
      "<start>这件衬衫穿着一件纯色图案的长袖背心和一条长裤。这件背心采用纯棉面料，纯色图案。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。\n",
      "<start>这位女士穿着一件纯色图案的长袖背心和一条长裤。这件背心采用纯棉面料，纯色图案。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>衬衫穿着长袖衬衫，纯棉面料，纯色图案，纯色图案和纯色图案。这件衬衫是纯棉的，有纯色的花纹。这件衬衫是纯棉的，有纯色的花纹。这件衬衫是纯棉的，有纯色的花纹。这件衬衫是纯棉的，有纯色的花纹。这件衬衫是纯棉的，有纯色的花纹。这件衬衫是纯棉的，有纯色的花纹。这件衬衫采用纯棉面料，有纯色图案\n",
      "299\n",
      "<start>这名女性穿着纯色图案的背心。背心采用纯棉面料和纯色图案。雌性戴着戒指<end>\n",
      "<start>这名女性穿着纯色图案的背心。这件背心是纯棉的，有纯色的花纹。雌性戴着戒指<end>\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。这件衬衫是纯棉的，有纯色的花纹。女的穿一条长裤。这条裤子是纯棉的，有纯色的花纹。女的穿一条长裤。这条裤子是纯棉的，有纯色的花纹。雌性戴着戒指<end>\n",
      "399\n",
      "<start>这名女性穿着印有图案的背心。背心是棉布的。它有一个圆形的领口。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>这名女性穿着印有图案的背心。背心是棉布的。它有一个圆形的领口。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>这个人穿的衬衫袖子剪掉了，棉质面料和图案。它有一个圆形的领口。这位女士穿的裤子很长。这条裤子是棉布和图案的<end>\n",
      "499\n",
      "<start>这位女士穿着一件带有纯色图案的长袖毛衣。这件毛衣是棉布的。它的领口是圆领的。这条裤子是牛仔面料和纯色图案的。雌性戴着戒指<end>\n",
      "<start>鞋面采用长袖、棉质面料和图案设计。它的领口是圆领的。这条短裤是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "<start>鞋面采用剪裁袖子、棉质面料和纯色图案。这件毛衣是棉布的，领口是吊带的。这条裤子是纯棉的，有纯色的花纹<end>\n",
      "599\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。这种布料是纯棉的，有纯色的花纹<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。这种布料是纯棉的，有纯色的花纹<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。这件衬衫是棉布的，领口是圆领。这条裤子是用牛仔布织成的，有纯色的花纹<end>\n",
      "699\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。这种布料是纯棉的，有纯色的花纹。雌性戴着戒指<end>\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。这种布料是纯棉的，有纯色的花纹。雌性戴着戒指<end>\n",
      "<start>这个人穿的衬衫袖子剪掉了，棉质面料和图案。它的领口是圆领的。这个人穿的裤子有三分长。这条裤子是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "799\n",
      "<start>此人穿着纯色图案的无袖背心和三分裤。这件衬衫是棉布的，领口是圆的。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>此人穿着纯色图案的无袖背心。背心是棉布的。这件衬衫的领口是圆的。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>她的衬衫采用长袖、棉质面料和图案设计。这件衬衫是棉布的，领口是圆的。这条裤子是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "899\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它的领口是圆领的。这条裤子是纯棉的，有纯色的花纹。她的手腕上有一个配件<end>\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。这件背心是棉布的。这条裤子是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "999\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。它的领口是圆的。这条裤子是牛仔面料和纯色图案的<end>\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。它的领口是圆的。这条裤子是牛仔面料和纯色图案的<end>\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。这件衬衫是棉布的，领口是吊带的。这条裤子是纯棉的，有纯色的花纹。这个人穿着一条长裤，棉布和纯色图案。这位女士穿着一条长裤，纯棉面料，纯色花纹。这个人戴着戒指<end>\n",
      "1099\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆形的领口。下面的衣服很长。这布料是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆形的领口。下面的衣服很长。这布料是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "<start>这个人穿着一件纯色图案的长袖衬衫。这件背心是棉布的。它有一个圆形的领口。这位女士穿的裤子很长。这条裤子是纯棉的，有纯色的花纹。这个人戴着戒指<end>\n",
      "1199\n",
      "＜开始＞＜结束＞\n",
      "＜开始＞＜结束＞\n",
      "<start>此人身穿纯色花纹背心。这件背心是棉布的，领口是圆的。这条裤子是纯棉的，有纯色的花纹<end>\n",
      "1299\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和图案设计。它有一个圆领。下面的衣服很长。面料是牛仔布，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和图案设计。它有一个圆领。下面的衣服很长。面料是牛仔布，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和图案设计。它有一个圆领。下面的衣服很长。面料是牛仔布，有纯色的花纹<end>\n",
      "1399\n",
      "<start>上衣无袖，棉质面料，纯色图案。它的领口是圆领的。下面的衣服很长。这布料是纯棉的，有纯色的花纹。他的脖子上有一个配饰。她的手指上有一枚戒指。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰\n",
      "<start>上衣无袖，棉质面料，纯色图案。它的领口是圆领的。下面的衣服很长。这布料是纯棉的，有纯色的花纹。他的脖子上有一个配饰。她的手指上有一枚戒指。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰。他的脖子上有一个配饰\n",
      "<start>上衣无袖，棉质面料，纯色图案。它的领口是圆领的。下面的衣服很长。这布料是纯棉的，有纯色的花纹。她的手指上有一枚戒指<end>\n",
      "1499\n",
      "<start>此人穿着纯色图案的无袖背心。这件背心是棉布的。它有一个吊带领口。这位女士穿的裤子有三分长。这条裤子采用棉布和图案。她的手腕上有一个配件<end>\n",
      "<start>此人穿着纯色图案的无袖背心。这件背心是棉布的。它有一个吊带领口。这位女士穿的裤子有三分长。这条裤子采用棉布和图案。她的手腕上有一个配件<end>\n",
      "<start>这位女士穿着一件纯色图案的无袖背心和一条长裤。这件背心是棉布的。这条裤子采用棉布和图案。这位女士戴着一枚戒指<end>\n",
      "1599\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。面料是牛仔布，有纯色的花纹。她的手腕上有一个配件。她的手指上有一枚戒指<end>\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。它的领口是圆领的。下面的衣服很长。面料是牛仔布，有纯色的花纹。她的手腕上有一个配件。她的手指上有一枚戒指<end>\n",
      "<start>鞋面服装采用剪裁袖子、棉质面料和图案设计。它的领口是圆领的。下面的衣服很长。这布料是纯棉的，有纯色的花纹。背心有一个圆形的领口。此人穿着一条长裤，牛仔面料，纯色图案。这个人所穿的外衣是棉布和纯色的花纹。这个人戴着戒指<end>\n",
      "1699\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。它有一个圆形的领口。下面的衣服有三分长。面料是棉质的，上面有图案。她的手腕上有一个配件<end>\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆形的领口。下面的衣服有三分长。面料是棉质的，上面有图案。她的手腕上有一个配件<end>\n",
      "<start>她的衬衫有长袖、棉质面料和纯色图案。背心的领口是圆领的。这条裤子是牛仔面料和纯色图案的。雌性戴着戒指<end>\n",
      "1799\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n",
      "<start>上衣采用长袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n",
      "<start>上衣采用短袖、棉质面料和纯色图案。它有一个圆领。下面的衣服有三分长。面料是牛仔布，有纯色的花纹。这个人戴着戒指<end>\n"
     ]
    }
   ],
   "source": [
    "i = 99\n",
    "while (i < 1800):\n",
    "    print(i)\n",
    "    try:\n",
    "        model = torch.load(f'./model/MYMODL/mymodl_0_{i}.pth')\n",
    "    except:\n",
    "        model = torch.load(f'./model/MYMODL/mymodl_1_{i}.pth')\n",
    "    model.eval()\n",
    "    e_textss = model.generate_by_beamsearch(imgs, 5, 102)\n",
    "    e_textsm = model.generate_by_beamsearch(imgm, 5, 102)\n",
    "    e_textsl = model.generate_by_beamsearch(imgl, 5, 102)\n",
    "    print(translate(fromtexttosentence(e_textss, all_words)))\n",
    "    print(translate(fromtexttosentence(e_textsm, all_words)))\n",
    "    print(translate(fromtexttosentence(e_textsl, all_words)))\n",
    "    i += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34be8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#结合rouge和主观认知，选择模型加载保存作为系统嵌入的模型\n",
    "torch.load('./model/MYMODL/mymodl_0_799.pth')\n",
    "torch.save(model, f'./model/MYMODL/mymodl.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e40fbf-a731-4638-99fe-4f72cea1e4fc",
   "metadata": {},
   "source": [
    "七、总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52a101-25a6-4d64-a769-53bf5b581b1e",
   "metadata": {},
   "source": [
    "\n",
    "1、通过本实验，加深了对编码器解码器结构的理解，完成了从image到text的生成尝试，为多模态应用和进一步打开深度学习的世界打下了厚实的实践基础。\n",
    "\n",
    "2、本模型的工作量在于手写实现vgg19+gru的编解码结构，深入理解了图片编码数据嵌入序列模型的机制，通过简单的参数设置和调优训练，基本实现了从服装图片生成文本描述的任务。\n",
    "\n",
    "3、创新点在于：对比两种评测指标在模型描述生成上的表现，同时引入api翻译生成中文描述以直观感知描述准确度，评测和调优相对客观和完善。\n",
    "\n",
    "4、局限在于：\n",
    "\n",
    "（1）训练数据词汇量少、丰富性不足；\n",
    "\n",
    "（2）算力限制了模型超参数的调优，因为每重新加载模型，就会产生大量未释放的内存，造成内存溢出的隐患，而若想要消除隐患，则需每次重启内核，重新加载词典和Dataloader，时间开销不可估量；\n",
    "\n",
    "（3）内存和算力限制了模型训练，由于单步batchsize为1、workers为0才能保证内存足够适应后续训练，数据加载速度缓慢，加之vgg19模型本身计算复杂度高，平均每训练100个数据耗时近10分钟，按训练集大小9000余、验证集大小1000余来算，每训练一个epoch需要至少15h，同时每验证一次评估两个指标大约需20分钟，即使900步评估一次也需要6个小时，即训练一个完整的epoch需要电脑在虚拟环境下不眠不休工作一整天，极大地限制了模型的训练；\n",
    "\n",
    "（4）vgg19作为imageencoder提取整体特征对于背景纯白的模特服装图片来讲，提出的特征差异较难满足本实验要求，应选择更细粒度的模型，同时也要兼顾计算复杂度，比如固定预训练模型的某些层不动，只做微调（因为9000个数据对于本例来说数据量已经算相对充足的了），以此来实现进一步优化；\n",
    "\n",
    "（5）有研究表明，gru作为解码器训练更快但LSTM在数据量足够的情况下表征能力更强，本例后续也可以使用LSTM实现解码器以此进一步探究在该图像描述生成任务下，针对同一编码器，两者对本实验的适应度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236b5ac-e2da-4c08-8ee1-211a2d9bc54e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
